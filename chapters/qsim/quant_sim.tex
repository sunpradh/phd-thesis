%----------------------------------------
% SECTION: Quantum simulation
%----------------------------------------
\section{Quantum simulation}
\label{sec:quantum_simulation}

Simulating quantum mechanics is a very challenging task \cite{manin1980computable, feynman1982simulation}, especially if one is interested in many-body systems.
The description of a state requires a large number of variables, for keeping track of all the quantum amplitudes, and it grows exponentially with the system size.
Hence, one would have an \emph{exponential explosion} in terms of \emph{classical} resources (like for example computer memory), which clearly is not suitable.

If simulating a quantum system is not a task for classical machines, then it should be a task for quantum machines \cite{feynman1982simulation, georgescu2014simulation, hauke2012simulators, kendon2010quantum, buluta2009simulators}.
The possibility of using quantum devices for simulating physics was first envisioned by Feynman in his seminal talk \cite{feynman1982simulation}.
The main idea is to encode the \ac{dof} of an ideal mathematical model of a physically relevant system into a controllable and reliable quantum system.
In other words, a \emph{quantum simulator} is an experimental system that mimics a simple model, or a family of simple models \cite{hauke2012simulators}.
Using quantum physics for simulating quantum physics itself may seem like fighting fire with fire, but it is actually a powerful idea.
We will no longer need an exponentially large number of variables for describing the target system, because the \ac{dof} of the target system and the simulator would be in a one-to-one correspondence.
Therefore, the size of a quantum computer would only be proportional to the size of the quantum system it intends to simulate, \emph{without} an exponential explosion in \emph{quantum} resources.

In this perspective, it would seem that one would need a specific quantum simulator for simulating a specific class of models.
This is not necessarily true with a \emph{quantum computer} \cite{feynman1985quantum, nielsen2010quantum, schleich2007elements, stolze2008quantum}.
The idea for such a device was put forward in \cite{feynman1982simulation, feynman1985quantum} and it would act as a \emph{universal quantum simulator}.
This has proven by LLoyd in \cite{lloyd1996simulator}.
The caveat is that the target system and its evolution would need some \emph{digitalization} scheme beforehand, because a quantum computer uses discrete \ac{dof}, the \emph{qubits}, so they are not suited for continuous-variable computation.
This is analogous to the case of classical computers, where real numbers have to be truncated and represented with a finite-size register of bits.
On the other hand, a problem-specific simulator can potentially uses some kind of physical platform which allows for continuous \ac{dof} \cite{kendon2010quantum, wagner2010continuous}.

In general, \emph{\acf{qs}} can be (loosely) defined as simulating a quantum system by quantum mechanical means.
There are three paths that can be taken in this regard \cite{georgescu2014simulation}:
\begin{itemize}
    \item Digital \acl{qs}
    \item Analog \acl{qs}
    \item Quantum Information inspired algorithms for classical simulation
\end{itemize}
We will discuss briefly each one of them.
By \emph{quantum simulator} we mean a \emph{controllable} quantum system used to simulate or emulate other quantum systems.
We see that only digital and analog \ac{qs}s employ a quantum simulator.
The last option employs techniques, inspired by quantum information theory, that make it possible to truncate and approximates quantum states in order to have efficient classical simulations.


\begin{figure}[t]
    \centering
    \input{assets/figures/quantum_simulator.tex}
    \caption{Schematic picture of a quantum simulator.}
\end{figure}


%
% SUBSECTION: Digital quantum simulations
%
\subsection{Digital quantum simulations}
\label{sub:digital_quantum_simulations}

The digital approach to \ac{qs} employs the \emph{circuit model} of quantum computation \cite{nielsen2010quantum, deutsch1989quantum}.
This model is analogous to the circuit model of classical computation, where one works with \emph{bits}, the smallest possible amount of information, an on--\emph{or}--off state, and a minimal set of \emph{logical operators} (like \texttt{NOT}, \texttt{AND}, \texttt{OR}, etc\dots).
In quantum computation, the set up is the same but with some key differences:
bits are substituted with \emph{qubits} and the logical operators with \emph{unitary operators}.

A bit can only have two values, either $0$ or $1$.
In quantum computing these values are elevated to two \emph{orthonormal} states $\ket{0}$ and $\ket{1}$.
Therefore, the bits are substituted with \emph{qubits}, which are two-levels quantum systems.
A generic state of a qubit is $\ket{\psi} = \alpha \ket{0} + \beta \ket{1}$, with the normalization condition $\alpha^2 + \beta^2 = 1$, and the complex amplitudes $\alpha$ and $\beta$ encodes the carried information.
A visual representation of the Hilbert space of a qubit is given by the Bloch sphere, see Fig.~\ref{fig:bloch_sphere}.
A set of qubits is called a \emph{quantum register} and they encode the state of the quantum computational machine, the equivalent of the tape of a Turing machine.


\begin{figure}[t]
    \SideFigure[label=fig:bloch_sphere, desc={Bloch sphere}]{%
        \input{assets/figures/bloch_sphere.tex}
    }{%
        Picture of a Bloch sphere.
        A generic state of a qubit can be written as
        $\ket{\psi} = \cos \frac{\theta}{2} \ket{0} + e^{i \varphi} \sin \frac{\theta}{2} \ket{1}$, so it is fully described by a two angles $\theta$ and $\phi$.
        For this reason, the Hilbert space of a qubit can be visualized as a two-dimensional sphere.%
    }
\end{figure}


The logical operators, or \emph{gates}, of classical computation are single-bit or double-bit functions that have only a single-bit output.
This makes classical computation \emph{non-reversible}\footnote{%
    There exist models of classical computation that are reversible, see \cite{fredkin1982logic}, which will not be discussed here and are not very common in every-day applications.
    In \cite{fredkin1982logic} a universal \emph{three-bits} gate is introduced that allows for reversible computation.%
}.
The idea behind quantum computing is to use the time-evolution of an ad-hoc quantum machine for performing computation.
Time-evolution is a \emph{unitary} process, which means that is reversible.
Hence, the non-reversible model of classical computation is not suited for quantum computing.
There is no one-to-one correspondence between the operations on a classical machine and those on a quantum machine.
Logical operations on a quantum computer, also called \emph{quantum gates}, have to implemented through \emph{unitary operators} that act on the quantum register.
A succession of logical operator, therefore, is equivalent to the product of these unitary operators.
This makes the whole computation a unitary process, hence reversible.

It is known, in classical computing, that only a minimal set of logical gates are actually needed in order to perform any computation.
For example, with a \texttt{NOT} gate and a \texttt{AND} gate is possible to implement every other possible logical function (actually only the \texttt{NAND} gate is necessary).
A similar result is true also for quantum computing \cite{barenco1995gates}.
One only needs a minimal set of quantum gates in order to implement any unitary operators with arbitrary precision.
Similar to the classical case, for quantum computing we only need single-qubit and two-qubits gates.
The two-qubits gates have an important role, because they allow to introduce \emph{entanglement}, which is the secret ingredient that makes quantum computing distinct from classical computing.
This minimal set usually entails a set of single-qubit and one two-qubits entangling gate (like the \texttt{CNOT} gate).
In Fig.~\ref{fig:quantum_gates} some example of quantum gates are shown, while in Fig.~\ref{fig:quantum_fourier} an example of a quantum circuit can be found.

\begin{figure}[t]
    \SideFigure[label=fig:quantum_gates, desc={Example of quantum gates}]{
        \input{assets/figures/quantum_gates.tex}
    }{
        Examples of quantum gates.
        From top to bottom:
        \emph{(i)} Hadamard gate $H$;
        \emph{(ii)} Phase gate $R_k$;
        \emph{(iii)} \texttt{CNOT} (controlled \texttt{NOT}) gate.
    }
\end{figure}

\medskip

Even though it has been proven that ``anything'' can be simulated on a quantum computer \cite{lloyd1996simulator}, not all unitary operations can be simulated \emph{efficiently}.
The time-evolution of the target quantum system requires \emph{digitalization}, which means that it has to be decomposed in smaller steps in order to be encodable as a sequence of quantum gates.
This is possible to an arbitrary precision thanks to the Trotter-Suzuki product formula for the exponentiation of complex matrices:
\begin{equation}
    e^{A + B}  = \lim_{n \to \infty} \qty( e^{A/n} e^{B/n} )^n.
\end{equation}
In most physically interesting case, the Hamiltonian is a sum of non-commuting terms:
\begin{equation*}
    H = \sum_{l} H_{l},
\end{equation*}
where $\comm{H_l}{H_{l^{\prime}}} \neq 0$ for $l \neq l^{\prime}$.
In the case of a time-independent Hamiltonian, the time-evolution operator is given by
\begin{equation}
    U(t) = e^{-i t \sum_{l} H_l }
    \quad \text{such that} \quad
    U(t) \ket{\psi(0)} = \ket{\psi(t)}.
    \label{eq:time_evolution_operator}
\end{equation}
In order to implement \eqref{eq:time_evolution_operator} on a quantum operator, the time-evolution has to be divided in $N$ steps of length $\Delta t$, such that $t = N \Delta t$ and $U(t) \simeq (U(\Delta t))^N$.
For each single time step we can apply the first-order Trotter-Suzuki formula \cite{nielsen2010quantum, somma2002simulating} for the time-evolution operator:
\begin{equation}
    U(\Delta t)
    = e^{- i \Delta t \sum_{l} H_l}
    = \prod_{l} e^{-i \Delta t H_l} + O(\Delta t^2).
    \label{eq:trotter_time_evolution}
\end{equation}

The drawback of Trotterization is that high accuracy comes at the cost of very small $\Delta t$ and therefore a very large number of quantum gates.
The scheme used in \eqref{eq:trotter_time_evolution} has some shortcomings, that can be improved with higher order decompositions that will necessarily introduce more complexities in the quantum circuit.
Moreover, some other types of methods have to be used in the case of time-dependent Hamiltonians \cite{wiebe2011simulation}.

\medskip

It should be stressed that we are still far from perfect digital quantum computation.
A typical quantum computer is affected by noise due to its interaction with the environment.
The effect of noise can corrupt the state of the quantum register, by flipping or dephasing the qubits for example.
Furthermore, interaction with an external environment will necessarily lead to \emph{decoherence} where all the ``quantumness'' of the system is lost \cite{zurek1991decoherence, schlosshauer2014decoherence, schlosshauer2019decoherence}.

It becomes clear that error correction is a necessity for \emph{fault-tolerant quantum computing} \cite{preskill1997faulttolerant, shor1996faulttolerant} but it can greatly increase the number of qubits needed for useful computations.
Indeed, it is said we are currently living in the \emph{noisy intermidiate-scale quantum} (NISQ) era of quantum computing \cite{preskill2018quantumcomputing}.
The term refers to moderately sized quantum computers (around 50--100 qubits) whose gates are still affected by noise but are not large enough to fully implement error correction.

\medskip

The typical setup for a digital simulation consists of three steps:
\begin{description}[font=\normalfont\itshape, labelsep=1.1em]
    \item[Initial-state preparation.] The quantum register is prepared in the initial state $\ket{\psi(0)}$.
        This step can be difficult by itself, and it is not always guaranteed that an efficient algorithm may exist.

    \item[Unitary evolution.] The circuit has to reproduce or simulate the action of a unitary operator $U$.
        This unitary operator is usually the time-evolution operator of the target system, which has to be decomposed in a sequence of smaller operation through trotterization, as explained before.

    \item[Final measurement.] After obtaining the wanted state $\ket{\psi(t)} = U \ket{\psi(0)}$, a \emph{measurement} is needed in order to extract relevant physical information.
        Instead of capturing the whole wave function $\ket{\psi(t)}$, with, for example, quantum tomography, one may proceed with the direct estimation of certain physical quantities, such as correlation functions or spectra of operators.
\end{description}


\begin{figure}[t]
    \centering
    \scalebox{0.75}{\input{assets/figures/quantum_fourier.tex}}
    \caption[Example of a quantum circuit]{
        Example of a quantum circuit.
        In particular this circuit executes the quantum Fourier transform \cite{nielsen2010quantum}.
        It uses some of the gates showed in Fig.~\ref{fig:quantum_gates}.
    }
    \label{fig:quantum_fourier}
\end{figure}


%
% SUBSECTION: Analog quantum simulations
%
\subsection{Analog quantum simulations}
\label{sub:analog_quantum_simulations}

Analog \ac{qs} is another type of approach to \ac{qs}, where one quantum system (the simulator) mimics or emulate another (the target) \cite{buluta2009simulators, wei1997simulation, arguello2019simulation, aspuruguzik2012photonic, blatt2012trappedions, bloch2012ultracold, houck2012superconducting, lewenstein2012ultracold}.
This approach is not based on building a universal machine, like a quantum computer, that can emulate any other system.
Instead, it focuses on recreating the features, or a subset of relevant features, of a chosen class of models in order to compute some physically relevant quantities.

Analog \ac{qs} follows the idea of \emph{analog computation}, where an experimental device is conceived for executing a specific algorithm, meaning that it is a specialized machine with some degree of controllability.
Analog computation is not a new idea, rather it is the oldest type of computing devised by mankind, and analog machines are the earliest types of computers to ever be used \cite{kendon2010quantum}.
Some historical examples can be the astrolabe for plotting the heavens (around 200 BC), the Antikythera mechanism for predicting astronomical routes (around 150 BC), or the mechanical differential analyser for integrating differential equations (around 1876) \cite{thomson1876integration}.

In an analog simulation, the Hamiltonian of the target $H^{\text{targ}}$, is directly mapped onto the Hamiltonian of the simulator, $H^{\text{sim}}$:
\begin{equation*}
    H^{\text{targ}} \longleftrightarrow H^{\text{sim}}.
\end{equation*}
Obviously, this is possible only if there is a mapping between the system and the simulator.
If $\ket{\phi(0)}$ is the initial state of the target, then it can be mapped to the initial state $\ket{\psi(0)}$ of the simulator, via an operator $\mathcal{O}$, i.e.~$\ket{\psi(0)} = \mathcal{O} \ket{\phi(0)}$.
Next, the simulator would perform the desired time evolution $U(t) \ket{\psi(0)} = \ket{\psi(t)}$.
The result then can be mapped back to a state of the target system via $\mathcal{O}^{-1}$, i.e.~$\mathcal{O}^{-1}\ket{\psi(t)} = \ket{\phi(t)}$.
In this case the Hamiltonians would be related by the mapping $\mathcal{O}$, $H^{\text{sim}} = \mathcal{O} H^{\text{targ}} \mathcal{O}^{-1}$.
Note that the simulator may only partly reproduce the dynamics of the target, or simulate some effective description of the system.
The choice of the mapping depends on what needs to be simulated and on the capabilities of the simulator \cite{georgescu2014simulation}.
Finding the mapping in an analog \ac{qs} might look, at first, simpler than finding the most efficient gate decomposition of a Hamiltonian, but it is not always true and there are no recipes ready for constructing these mappings in a general case.
% The obvious drawback of AQS is that the quantum simulators are problem specific, but on the other hand, given that they do not require a full quantum computer, they are more feasible in the near-term.

Initial state preparation is not such a topic in analog \ac{qs}, as it is in digital \ac{qs}.
This is based on the assumption that the target system and the simulator are presumed to be very similar.
It is expected that the preparation of the initial state can occur naturally in processes mimicking the natural relaxation of the simulated system to an equilibrium state.
Moreover, analog \ac{qs} has the natural advantage that physical quantities can be measured directly, without the need of special schemes like in digital \ac{qs}, which can yield direct information about the target system \cite{hauke2012simulators}.

One important advantage of analog \ac{qs} is that fact that it does not require a fully fledged quantum computer.
In fact, the simulator does not even need to be a quantum computer at all.
This possibly makes analog \ac{qs} much more achievable from the experimental point of view.
Many different platforms are already available (see also Fig.~\ref{fig:analog_simulators}):
\begin{itemize}
    \item ultracold atoms and molecules \cite{lewenstein2012ultracold, bloch2012ultracold, bloch2008ultracold, lin2009ultracold, muller2012ions, aidelsburger2011ultracold};
    \item trapped ions \cite{blatt2012trappedions, muller2012ions, johanning2009ions, schneider2012ions};
    \item photons \cite{aspuruguzik2012photonic, angelakis2017quantum};
    \item polaritons \cite{angelakis2017quantum, hartmann2006polaritons};
    \item nuclear magnetic resonance (NMR) systems \cite{somaroo1999simulation, tseng1999nmr};
    \item artificial lattices \cite{singha2011lattice};
    \item superconducting qubits \cite{houck2012superconducting, makhlin2001superconducting, devoret2004superconducting, you2005superconducting, pritchett2010superconducting}.
\end{itemize}

Analog \ac{qs} can be useful even in the presence of errors, up to a certain tolerance level, because it would still be able to give qualitative answers.
Suppose one is interested in knowing if whether a certain set of physical conditions leads to a given quantum phase transition.
Even without the full quantitative description or the perfect tuning of the control parameters, an analog simulator would, potentially, still be able to show the presence or not of a phase transition.
Furthermore, due to the analog nature of these simulators, standard error correction and fault tolerance are not allowed \cite{hauke2012simulators}, while the level of controllability depends on the type of platform used.
For example, in the case of ultracold atoms in optical lattices the typical control parameters involve lattice parameters (laser wavelength, geometry, dimensionality, etc\dots), temperature and other thermodynamical control parameters, as well as atomic interaction strength \cite{lewenstein2012ultracold}.


\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{assets/figures/quantum_simulators.png}
    \caption[Examples of analog quantum simulators]{
        Figure taken from \cite{buluta2009simulators}.
        Examples of analog quantum simulators:
        \emph{(a)} atoms in optical lattices,
        \emph{(b)} one-dimensional or
        \emph{(c)} two-dimensional arrays of cavities;
        \emph{(d)} ions in linear chains,
        \emph{(e)} two-dimensional arrays of planar traps, or
        \emph{(f)} two-dimensional Coulomb crystal;
        \emph{(g)} electrons in quantum dot arrays created by a mesh gate,
        \emph{(h)} in arrays of superconducting circuits, or
        \emph{(i)} trapped on the surface of liquid helium.
        For more details see \cite{buluta2009simulators, georgescu2014simulation}.
    }
    \label{fig:analog_simulators}
\end{figure}


%
% SUBSECTION: Quantum-inspired algorithms
%
\subsection{Quantum-inspired algorithms}
\label{sub:quantum_inspired_algorithms}

Classical simulations of quantum systems are usually done using one of the following methods \cite{hauke2012simulators}:
\begin{itemize}[itemsep=0pt]
    \item Quantum \ac{mc}.
    \item Systematic perturbation theory.
    \item \Ac{ed}.
    \item \Ac{dmrg}.
\end{itemize}
Each of these methods has its problems.
Quantum \ac{mc} methods can work with large systems but fails for fermionic systems due to the sign problem \cite{sandvik2010computational, troyer2010computational}.
Perturbation theory is applicable only when there is a small coupling constant, so it fails for strongly interacting systems.
\Ac{ed} works only for rather small systems \cite{sandvik2010computational, troyer2010computational}.
\Ac{dmrg} is a variation methods that has been proven to work also for strongly interacting systems \cite{schollwock2011dmrg, mcculloch2007dmrg, dechiara2008dmrg}.
It has been proven to be of great success for one-dimensional systems, while for two-dimensional models it can be quite limited \cite{stoudenmire2012dmrg}.

Thanks to the development of quantum information, new \emph{classical algorithms} have been invented for the simulation of many-body systems that much more exploit the quantum nature of these systems.
One of the most groundbreaking example of quantum-inspired algorithms is the use of \emph{\ac{tn} states} \cite{orus2014tensor, verstraete2004algo, verstraete2008tensor, verstraete2004dmrg, vidal2008simulation, cirac2009tensor}.
\Acp{tn} make it possible to ``compress'' the information about a many-body wave function by expressing it as a \emph{contraction} of a network of tensors (as suggested by the name).

In details, to each physical site we associate a tensor with a number of indices (or legs).
One of these indices is called the \emph{physical index} of the tensors, which runs over the basis of the local Hilbert space.
The other indices are \emph{auxiliary indices}, their dimension is governed by a parameter $\chi$ called the \emph{bond dimension} and are ``connected'' to other sites.
Roughly speaking, these auxiliary indices encodes the entanglement information between the connected sites.

To make it more clear, consider a one-dimensional open chain (with $L$ sites), where each site has a $d$-dimensional local Hilbert space with basis $\{\ket{i}, i = 1,\dots,d\}$.
A general global state $\ket{\Psi}$ of the whole chain can be written as
\begin{equation}
    \ket{\Psi} = \sum_{i_1, \dots, i_L} C_{i_1, \dots, i_L} \ket{i_1 \cdots i_L}.
\end{equation}
It is easy to see that the whole state is encoded in the $L$-th order tensor $C_{i_1, \dots, i_L}$ and the indices $i_n$ are called physical indices.
Notice that $C_{i_1, \dots, i_L}$ has $d^L$ entries.
Through \emph{\ac{svd}} it is possible to factorize the tensor $C_{i_1, \dots, i_L}$ into $L$ tensors $A^{i_n}$, one for each site \cite{schollwock2011dmrg}:
\begin{equation}
    C_{i_1, \dots, i_L}
    = \sum_{\alpha_1, \dots, \alpha_{L-1}}
    A^{i_1}_{\alpha_1}
    A^{i_2}_{\alpha_1, \alpha_2}
    \cdots
    A^{i_{L-1}}_{\alpha_{L-2}, \alpha_{L-1}}
    A^{i_L}_{\alpha_{L-1}}.
    \label{eq:mps_decomposition}
\end{equation}
The indices $\alpha_n$ are called auxiliary indices.

The order of $\alpha_n$ depends on the number of Schmidt eigenvalues of the bipartition that separates the first $n$ sites from the rest.
In other words, it depends on the entanglement entropy between the first $n$ sites of the chain and the rest.
Not all the Schmidt eigenvalues are of the same importance, therefore each tensor $A^{i_n}$ can be optimized by discarding the Schmidt eigenvalues under a certain threshold.
In this way we compress the wave-function, by preserving the information that best represent the entanglement in the state.
The order of the indices $\alpha_n$ is called the \emph{bond-dimension}, often denoted $\chi$, and it is this parameter that fine tunes the amount of entanglement.
Notice that with $\chi$ fixed, the right hand side of \eqref{eq:mps_decomposition} has only around $L d \chi^2$ entries, which scales better that $d^L$.
If the system has a finite amount of entanglement, then there is an optimal value for the bond dimension $\chi$.
This would mean that we do not really need all the $d^L$ entries of $C$, but the $L d \chi^2$ entries of \eqref{eq:mps_decomposition} are sufficient to faithfully represent $\ket{\Psi}$.

For a large class of physically relevant models, the ground state is gapped and has, in a certain sense, a finite amount of entanglement, which can be explained by the finite correlation length.
This fact is expressed by the so-called \emph{area law}, where the entanglement between two partitions of the system grows with size of the boundary, the area between the two partitions, and not with the size of the partition itself \cite{vidal2003arealaw, calabrese2004qft, srednicki1993area, plenio2005area}.
The main advantage of \ac{tn} methods is their ability to capture this area law, which lead to an efficient computation of the ground states of these models.

\Acp{tn} were first inspired by the ground state of the AKLT model \cite{affleck1987aklt}, and from there different types \acp{tn} were developed.
The paradigmatic example of \acp{tn} are the \emph{\acp{mps}} in one-dimension \cite{vidal2008simulation, schollwock2011dmrg}, and the \emph{\acp{peps}} in two dimensions \cite{verstraete2004algo, jordan2008ipeps}.
Some other variants of \acp{tn} exists, like \emph{Tree \acp{tn}} \cite{tagliacozzo2009tree, fannes1992trees} or \emph{\ac{mera}} \cite{evenbly2013mera, vidal2007entanglement, evenbly2009entanglement}.

\begin{figure}[t]
    \centering
    \input{assets/figures/tensor_networks.tex}
    \caption{Examples of \acp{tn}}
\end{figure}

